{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edgarmp\\AppData\\Local\\Temp\\ipykernel_27720\\411096512.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.autonotebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "from pinecone_text.sparse import BM25Encoder\n",
    "import nltk\n",
    "\n",
    "root_dir = Path(os.getcwd()).parent.parent\n",
    "sys.path.insert(0, str(root_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\edgarmp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# from src.d00_utils.parsing import extract_index_from_doc\n",
    "from src.d01_data.data import read_json, create_index_if_not_exists, upsert_vectors_in_batches\n",
    "from src.d00_utils.utils import dict_to_document, metadata_to_uuid, generate_sparse_vector_in_batches\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "load_dotenv('../../.env')\n",
    " \n",
    "raw_path = root_dir / 'data' / '01_raw'\n",
    "intermediate_path = root_dir / 'data' / '02_intermediate'\n",
    "output_path = root_dir / 'data' / '04_model_output'\n",
    "\n",
    "files_path = [Path(p) for p in glob(str(intermediate_path / '*.json'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index chatbot-leyes already exists\n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone()\n",
    "pc_index = create_index_if_not_exists(client=pc, index_name='chatbot-leyes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2774 documents have been created\n"
     ]
    }
   ],
   "source": [
    "# Converting the json to Documents object with its content and metadata\n",
    "all_articles = []\n",
    "for file in files_path:\n",
    "    articles = read_json(file)\n",
    "    all_articles.extend(dict_to_document(estructured_dict=articles, origen=file.stem))\n",
    "    \n",
    "print(f'{len(all_articles)} documents have been created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks for duplicates chunks\n",
    "final_uuids = metadata_to_uuid(all_articles)\n",
    "\n",
    "assert len(final_uuids) == len(set(final_uuids)), 'THE ARE DUPLICATED IDS'\n",
    "del final_uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46eb1de80c2b4d0ab53b3180e4b3a814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and saving the BM25Encoder\n",
    "bm25 = BM25Encoder(language='spanish')\n",
    "bm25.fit([doc.page_content for doc in all_articles])\n",
    "bm25.dump(output_path / 'bm25_values.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting chunks \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [01:19<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "print('Creating embeddings')\n",
    "vectors = generate_sparse_vector_in_batches(documents=all_articles,\n",
    "                                            embedding_client=pc.inference,\n",
    "                                            fitted_bm25=bm25,\n",
    "                                            batch_size=64)\n",
    "print('Upserting chunks ')\n",
    "upsert_vectors_in_batches(vectors=vectors, index=pc_index, batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
