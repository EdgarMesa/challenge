{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edgarmp\\AppData\\Local\\Temp\\ipykernel_1292\\4250820510.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from tqdm.autonotebook import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import pymupdf\n",
    "\n",
    "root_dir = Path(os.getcwd()).parent.parent\n",
    "sys.path.insert(0, str(root_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.d00_utils.parsing import (extract_index_from_doc,\n",
    "                                   get_hierarchy,\n",
    "                                   extract_previous_hierarchy,\n",
    "                                   extract_final_hierarchy,\n",
    "                                   extract_paragraphs)\n",
    "\n",
    "from src.d01_data.data import json_dump\n",
    "\n",
    "raw_path = root_dir / 'data' / '01_raw'\n",
    "intermediate_path = root_dir / 'data' / '02_intermediate'\n",
    "\n",
    "files_path = [Path(p) for p in glob(str(raw_path / '*.pdf'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d172e8e991364a61b622389b3572ab2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file c:\\Users\\edgarmp\\Desktop\\ejemplos\\chatbot\\data\\01_raw\\Constitucion Española.pdf\n",
      "Última página del índice 2\n",
      "Archivo guardado exitosamente como c:\\Users\\edgarmp\\Desktop\\ejemplos\\chatbot\\data\\02_intermediate\\Constitucion Española.json\n",
      "\n",
      "Parsing file c:\\Users\\edgarmp\\Desktop\\ejemplos\\chatbot\\data\\01_raw\\Código Civil.pdf\n",
      "Última página del índice 12\n",
      "Archivo guardado exitosamente como c:\\Users\\edgarmp\\Desktop\\ejemplos\\chatbot\\data\\02_intermediate\\Código Civil.json\n",
      "\n",
      "Parsing file c:\\Users\\edgarmp\\Desktop\\ejemplos\\chatbot\\data\\01_raw\\Código Penal.pdf\n",
      "Última página del índice 8\n",
      "Archivo guardado exitosamente como c:\\Users\\edgarmp\\Desktop\\ejemplos\\chatbot\\data\\02_intermediate\\Código Penal.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files_path):\n",
    "    print(f'Parsing file {file}')\n",
    "    \n",
    "    doc = pymupdf.open(file)\n",
    "    \n",
    "    # Separates the index pages from the rest\n",
    "    doc, indexes_pages = extract_index_from_doc(doc=doc)\n",
    "    \n",
    "    # Joins all the text of the pages and extracts the hierarchy\n",
    "    index_text = '\\n'.join([p.get_text() for p in indexes_pages])\n",
    "    jerarquia = get_hierarchy(index_text)\n",
    "    all_pages_text = '\\n'.join([p.get_text() for p in doc])\n",
    "    \n",
    "    \n",
    "    # Regex to find each Articulo in the text\n",
    "    pattern = r'^Artículo\\s+\\d+(?:\\s+bis)?\\.'\n",
    "\n",
    "    # Use re.findall with the MULTILINE flag to extract all occurrences.\n",
    "    matches = re.findall(pattern, all_pages_text, flags=re.MULTILINE)\n",
    "\n",
    "    # Regex to find special case of Articulo\n",
    "    combine_pattern = r'^\\s*(Artículos\\s+\\d+\\s+(?:a|y)\\s+\\d+\\.)\\s*'\n",
    "    combine_matches = re.findall(combine_pattern, all_pages_text, flags=re.MULTILINE)\n",
    "\n",
    "    if not combine_matches:\n",
    "        combine_matches = []\n",
    "\n",
    "    matches = matches + combine_matches\n",
    "    \n",
    "    \n",
    "    # Extract the previous hierarchical structure from the full text.\n",
    "    previous_hierarchy = extract_previous_hierarchy(texto=all_pages_text,\n",
    "                                                    articles=matches,\n",
    "                                                    jerarquia=jerarquia)\n",
    "\n",
    "    # Based on the previously extracted hierarchy, determine the final parent-child relationships.\n",
    "    final_parents = extract_final_hierarchy(hierarchy=previous_hierarchy,\n",
    "                                            origen=file.stem.lower())\n",
    "\n",
    "    # Extract paragraphs from the text based on the provided search words (article markers).\n",
    "    article_texts = extract_paragraphs(text=all_pages_text, \n",
    "                                        search_words=matches)\n",
    "    \n",
    "    # Making sure there is not article missing information\n",
    "    assert len(final_parents) == len(article_texts), 'Mismatch in articles information'\n",
    "    \n",
    "    # Combination of information of each article\n",
    "    combined_article_info = {}\n",
    "    for article in article_texts.keys():\n",
    "        combined_article_info[article] = f'{final_parents[article]}\\n{article_texts[article]}'\n",
    "        \n",
    "\n",
    "    # Savinf the result of parsing\n",
    "    json_dump(combined_article_info, intermediate_path / file.stem)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
